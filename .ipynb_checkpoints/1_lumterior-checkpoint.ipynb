{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "confident-transcription",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 플랫폼 업로드를 쉽게하기 위한 로컬 개발 코드\n",
    "- T3Q.ai(T3Q.cep + T3Q.dl): 빅데이터/인공지능 통합 플랫폼\n",
    "- 플랫폼 업로드를 쉽게하기 위하여 로컬에서 개발한 코드(파일0)를 아래의 설명을 참고하여 플랫폼 업로드 코드(파일1)를 개발한다.\n",
    "- 파일 0(파일명): 0_local_image_classification.ipynb\n",
    "-  파일 1(파일명): 1_local_platform_image_classification.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-delight",
   "metadata": {},
   "source": [
    "# 인공지능 통합플랫폼(T3Q.ai) 프로세스를 이해하고 인공지능 쉽게 하기"
   ]
  },
  {
   "cell_type": "raw",
   "id": "median-watershed",
   "metadata": {},
   "source": [
    "1. 머신러닝(Machine Learning)과 딥러닝(Deep Learning) 프로그래밍 패턴\n",
    "\n",
    "(1) 데이터셋 불러오기(Dataset Loading)\n",
    "(2) 데이터 전처리(Data Preprocessing)\n",
    "   - 데이터 정규화(Normalization)\n",
    "   - 학습과 테스트 데이터 분할(Train/Test Data Split) 등\n",
    "(3) 학습 모델 구성(Train Model Build)\n",
    "(4) 학습(Model Training)\n",
    "(5) 학습 모델 성능 검증(Model Performance Validation)\n",
    "(6) 학습 모델 저장(배포) 하기(Model Save)\n",
    "(7) 추론 데이터 전처리((Data Preprocessing)\n",
    "(8) 추론(Inference) 또는 예측(Prediction) \n",
    "(9) 추론 결과 데이터 후처리(Data Postprocessing) "
   ]
  },
  {
   "cell_type": "raw",
   "id": "foster-transcription",
   "metadata": {},
   "source": [
    "2. 빅데이터/인공지능 통합 플랫폼[ T3Q.ai ]에서 딥러닝 프로그래밍 하고 인공지능 서비스 실시간 운용하기\n",
    " - 4개의 함수로 딥러닝 프로그래밍 하고 인공지능 서비스 실시간 운용하기\n",
    "\n",
    "(1) train() 함수 \n",
    " - 데이터셋 불러오기(Dataset Loading)\n",
    " - 데이터 전처리(Data Preprocessing)\n",
    " - 학습 모델 구성(Train Model Build)\n",
    " - 학습(Model Training)\n",
    " - 학습 모델 성능 검증(Model Performance Validation)\n",
    " - 전처리 객체 저장\n",
    " - 학습 모델 저장(배포) 하기\n",
    "   에 필요한 코드 작성\n",
    "\n",
    "(2) init_model() 함수 \n",
    " - 전처리 객체 및 학습모델 객체 불러오기\n",
    "   에 필요한 코드 작성\n",
    "\n",
    "(3) inference_dataframe(input_data, model_info_dict) 함수\n",
    " - input_data 입력에 대한 추론 처리 기능\n",
    " - 추론시 입력 데이터에 대한 전처리(Data Preprocessing)\n",
    " - 추론(Inference) 또는 예측(Prediction) \n",
    " - 추론 결과 데이터 후처리(Data Postprocessing) \n",
    "\n",
    "(4) inference_file(files, model_info_dict) 함수\n",
    " - files 입력에 대한 추론 처리 기능\n",
    " - 추론시 입력 데이터에 대한 전처리(Data Preprocessing)\n",
    " - 추론(Inference) 또는 예측(Prediction) \n",
    " - 추론 결과 데이터 후처리(Data Postprocessing) "
   ]
  },
  {
   "cell_type": "raw",
   "id": "naughty-number",
   "metadata": {},
   "source": [
    "3. AI 알고리즘 관리 함수 설명\n",
    "1) [train.py] 학습 알고리즘 관리 함수\n",
    "\n",
    "import t3qai_client as tc\n",
    "from t3qai_client import T3QAI_TRAIN_OUTPUT_PATH, T3QAI_TRAIN_MODEL_PATH, T3QAI_TRAIN_DATA_PATH, T3QAI_MODULE_PATH\n",
    "\"\"\"\n",
    "(1) 설명:\n",
    "  # t3qai_client : 플랫폼과의 연동을 위한 클라이언트 모듈\n",
    "  # T3QAI_TRAIN_DATA_PATH : 업로드 된 데이터셋 경로\n",
    "  # T3QAI_TRAIN_MODEL_PATH : 학습 모델 저장 경로\n",
    "  # T3QAI_TRAIN_OUTPUT_PATH : 학습 결과 출력파일 저장 경로\n",
    "  # T3QAI_MODULE_PATH : AI 알고리즘 모듈 경로\n",
    "\"\"\"\n",
    "\n",
    "import logging \n",
    "    \n",
    "def train():\n",
    "    \"\"\"\n",
    "    (1) 입력: None\n",
    "    (2) 출력: None\n",
    "    (3) 설명: \n",
    "      # 데이터를 T3QAI_TRAIN_DATA_PATH 에서 불러오기\n",
    "      # 알고리즘 실행 파일과 같은 위치인 T3QAI_MODULE_PATH에서 필요한 폴더 및 파일 불러오기\n",
    "      # 데이터 전처리와 학습 모델을 구성하고 모델 학습을 수행\n",
    "      # 학습 모델의 성능을 검증하고 배포할 학습 모델을 저장\n",
    "      # 전처리 객체와 학습 모델 객체를 T3QAI_TRAIN_MODEL_PATH 에 저장\n",
    "      # 학습 결과를 파일(이미지, 텍스트 등) 형태로 T3QAI_TRAIN_OUTPUT_PATH 에 저장 \n",
    "    (4) 추가 설명: \n",
    "      # AI훈민정음 프로젝트에서는 코드 복잡성으로 인해 train_sub.py 파일 생성 후 import해서 사용함\n",
    "      # 함수 구조는 원형대로 유지\n",
    "      # 실질적인 기능을 하는 함수를 서브모듈 함수(exec_train)로 정의하여 사용함\n",
    "      # 함수명                         서브함수명\n",
    "      # train()                      exec_train()\n",
    "      # 함수의 정상적인 동작 체크를 위해 마지막 라인(the end line)에 로그 출력 수행\n",
    "    \"\"\"\n",
    "\n",
    "    exec_train()\n",
    "    \n",
    "    logging.info('[hunmin log] the end line of the function [train]')\n",
    "\n",
    "\n",
    "2) [inference_service.py] 추론 알고리즘 관리 함수\n",
    "\n",
    "import t3qai_client as tc\n",
    "from t3qai_client import T3QAI_INIT_MODEL_PATH, T3QAI_MODULE_PATH\n",
    "\"\"\"\n",
    "(1) 설명:\n",
    "  # T3QAI_INIT_MODEL_PATH : train() 함수에서 T3QAI_TRAIN_MODEL_PATH 에 저장한 전처리 객체와 \n",
    "                            학습 모델 객체 등을 추론 하기 위해 불러오는 경로\n",
    "  # T3QAI_MODULE_PATH : AI 알고리즘 모듈 경로\n",
    "\"\"\"\n",
    "\n",
    "def init_model():\n",
    "    \"\"\"\n",
    "    (1) 입력: None\n",
    "    (2) 출력: 전처리 객체와 학습 모델 객체 등을 딕셔너리(dictionary) 객체에 담아 리턴(return)\n",
    "    (3) 설명: \n",
    "      # T3QAI_TRAIN_MODEL_PATH에 저장한 전처리 객체와 학습 모델 객체 등을 불러오는 기능\n",
    "      # 전처리 객체와 학습 모델 객체 등을 딕셔너리(dictionary) 형태로 리턴(return)\n",
    "      # 리턴(return) 값을 inference_dataframe(input_data, model_info_dict), \n",
    "      inference_file(files, model_info_dict) 함수의 입력 model_info_dict 변수로 전달\n",
    "    (4) 추가 설명: \n",
    "      # AI훈민정음 프로젝트에서는 코드 복잡성으로 인해 inference_service_sub.py 파일 생성 후 import해서 사용함\n",
    "      # 함수 구조는 원형대로 유지\n",
    "      # 실질적인 기능을 하는 함수를 서브모듈 함수(exec_init_model)로 정의하여 사용함\n",
    "      # 함수명                            서브함수명\n",
    "      # init_model()                      exec_init_model()\n",
    "      # 함수의 정상적인 동작 체크를 위해 마지막 라인(the end line)에 로그 출력 수행      \n",
    "    \"\"\"\n",
    "\n",
    "    model_info_dict = exec_init_model()\n",
    "    \n",
    "    logging.info('[hunmin log] the end line of the function [init_model]')\n",
    "\n",
    "    return { **model_info_dict }\n",
    "\n",
    "\n",
    "def inference_dataframe(input_data, model_info_dict):\n",
    "    \"\"\"\n",
    "    (1) 입력: input_data, model_info_dict\n",
    "      # input_data : 추론시 입력한 데이터 형태\n",
    "      추론 입력 데이터\n",
    "      # model_info_dict: init_model() 함수의 return 값을 model_info_dict 변수로 전달\n",
    "        ## 학습 모델 객체 사용 예시       model = model_info_dict.get('model') 또는 \n",
    "                                         \t  model = model_info_dict['model']\n",
    "        ## 전처리(pca) 객체 사용 예시     pca = model_info_dict.get('pca') 또는\n",
    "                                          \t  pca = model_info_dict['pca']\n",
    "                                          \n",
    "    (2) 출력: 추론 결과 딕셔너리(dictionary) 형태 \n",
    "                  result = {'inference': inference_result}\n",
    "                            \n",
    "    (3) 설명: \n",
    "      # 전처리 객체를 사용하여 input_data(추론 입력 데이터)에 대한 전처리 수행\n",
    "      # 배포된 학습 모델(model)을 사용하여 input_data(추론 입력 데이터)에 대한 추론(예측)을 수행\n",
    "      # 추론 결과를 딕셔너리(dictionary) 형태로 리턴(return)\n",
    "\n",
    "    (4) 추가 설명: \n",
    "      # AI훈민정음 프로젝트에서는 코드 복잡성으로 인해 inference_service_sub.py 파일 생성 후 import해서 사용함\n",
    "      # 함수 구조는 원형대로 유지\n",
    "      # 실질적인 기능을 하는 함수를 서브모듈 함수(exec_inference_dataframe)로 정의하여 사용함\n",
    "      # 함수명                                                     \t        서브함수명\n",
    "      # inference_dataframe(input_data, model_info_dict)           exec_inference(input_data, model_info_dict)\n",
    "      # 함수의 정상적인 동작 체크를 위해 마지막 라인(the end line)에 로그 출력 수행            \n",
    "    \"\"\"\n",
    "    \n",
    "    result = exec_inference_dataframe(input_data, model_info_dict)\n",
    "    \n",
    "    logging.info('[hunmin log] the end line of the function [inference]')\n",
    "\n",
    "    return {**result}\n",
    "\n",
    "\n",
    "def inference_file(files, model_info_dict):\n",
    "    \"\"\"\n",
    "    (1) 입력: files, model_info_dict\n",
    "      # files: 추론 하고자 하는 파일 형태의 입력 \n",
    "      # model_info_dict: init_model() 함수의 return 값을 model_info_dict 변수로 전달\n",
    "        ## 학습 모델 객체 사용 예시       model = model_info_dict.get('model') 또는 \n",
    "                                          \t  model = model_info_dict['model']\n",
    "        ## 전처리(pca) 객체 사용 예시     pca = model_info_dict.get('pca') 또는\n",
    "                                          \t  pca = model_info_dict['pca']\n",
    "        \n",
    "    (2) 출력: a. 추론 결과 딕셔너리(dictionary) 형태 \n",
    "                  result = {'inference': inference_result}\n",
    "              b. 추론 결과 DownloadFile 형태\n",
    "                  result = DownloadFile(file_path=resultfilepath, file_name=filename1)\n",
    "                  result = DownloadFile(file_obj=resultfileobj, file_name=filename2)\n",
    "              c. 추론 결과 DownloadFile의 list형태\n",
    "                  result = [DownloadFile(file_path=resultfilepath, file_name=filename), \n",
    "                            DownloadFile(file_obj=resultfileobj, file_name=filename), ...]\n",
    "              \n",
    "    (3) 설명: \n",
    "      # 전처리 객체를 사용하여 files(추론 입력 데이터)에 대한 전처리 수행\n",
    "      # 배포된 학습 모델(model)을 사용하여 files(추론 입력 데이터)에 추론(예측)을 수행\n",
    "      # 추론 결과를 a.딕셔너리(dictionary) 형태, b.DownloadFile 형태, c.DownloadFile의 list 형태로 리턴(return)\n",
    "\n",
    "    (4) 추가 설명: \n",
    "      # AI훈민정음 프로젝트에서는 코드 복잡성으로 인해 inference_service.py 파일 생성 후 import해서 사용함\n",
    "      # 함수 구조는 원형대로 유지\n",
    "      # 실질적인 기능을 하는 함수를 서브모듈 함수(exec_inference_files)로 정의하여 사용함\n",
    "      # 함수명                                                     서브함수명\n",
    "      # inference_files(files, model_info_dict)                exec_inference_files(files, model_info_dict)\n",
    "      # 함수의 정상적인 동작 체크를 위해 마지막 라인(the end line)에 로그 출력 수행            \n",
    "    \"\"\"\n",
    "    \n",
    "    result = exec_inference_files(files, model_info_dict)\n",
    "    \n",
    "    logging.info('[hunmin log] the end line of the function [inference]')\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "guilty-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "# 그대로 두고,\n",
    "import logging, os\n",
    "\"\"\"\n",
    "from train_sub import exec_train\n",
    "import t3qai_client as tc\n",
    "from t3qai_client import T3QAI_TRAIN_OUTPUT_PATH, T3QAI_TRAIN_MODEL_PATH, \\\n",
    "                            T3QAI_TRAIN_DATA_PATH, T3QAI_TEST_DATA_PATH, T3QAI_MODULE_PATH\n",
    "\"\"\"\n",
    "\n",
    "def main():\n",
    "    result = None\n",
    "    result_msg = \"success\"\n",
    "    tc.train_start()\n",
    "    try:\n",
    "        train()\n",
    "    except Exception as e:\n",
    "        result = e\n",
    "        result_msg = e\n",
    "        logging.info('error log : {}'.format(e))\n",
    "    tc.train_finish(result, result_msg)\n",
    "\n",
    "def train():\n",
    "    exec_train()\n",
    "    logging.info('[hunmin log] the end line of the function [train]')\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "chronic-sympathy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport t3qai_client as tc\\nfrom t3qai_client import T3QAI_TRAIN_OUTPUT_PATH, T3QAI_TRAIN_MODEL_PATH,                             T3QAI_TRAIN_DATA_PATH, T3QAI_TEST_DATA_PATH, T3QAI_MODULE_PATH\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  train_sub.py\n",
    "\n",
    "\"\"\"\n",
    "import t3qai_client as tc\n",
    "from t3qai_client import T3QAI_TRAIN_OUTPUT_PATH, T3QAI_TRAIN_MODEL_PATH, \\\n",
    "                            T3QAI_TRAIN_DATA_PATH, T3QAI_TEST_DATA_PATH, T3QAI_MODULE_PATH\n",
    "\"\"\"\n",
    "\n",
    "# 비워서 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alike-deficit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference_service.py\n",
    "# 그대로 두고,\n",
    "\n",
    "\"\"\"\n",
    "from inference_service_sub import exec_init_model, exec_inference_dataframe, exec_inference_file\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel('INFO')\n",
    "\n",
    "def init_model():\n",
    "    model_info_dict = exec_init_model()\n",
    "    logging.info('[hunmin log] the end line of the function [init_model]')\n",
    "    return { **model_info_dict }\n",
    "\n",
    "\n",
    "def inference_dataframe(input_data, model_info_dict):\n",
    "    result = exec_inference_dataframe(input_data, model_info_dict)\n",
    "    logging.info('[hunmin log] the end line of the function [inference_dataframe]')\n",
    "    return { **result }\n",
    "\n",
    "\n",
    "def inference_file(files, model_info_dict):\n",
    "    result = exec_inference_file(files, model_info_dict)\n",
    "    logging.info('[hunmin log] the end line of the function [inference_file]')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b089ba9-9c12-403c-be6c-cb65ea78bfce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1eab2c-01e8-47e3-8777-35e9c19290b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.ndimage import maximum_position\n",
    "\n",
    "# models 내부 모듈 import\n",
    "from helper import build_generator\n",
    "\n",
    "from utils.logger import setup_logger\n",
    "from utils.editor import get_layerwise_manipulation_strength\n",
    "from utils.editor import manipulate\n",
    "\n",
    "\n",
    "\n",
    "def build_model(model_name, logger=None): # exec_init_model\n",
    "  \"\"\"Builds the generator by model name.\"\"\"\n",
    "  model = build_generator(model_name, logger=logger)\n",
    "  return model\n",
    "# build_model -> helper.py(build_generator) -> \n",
    "# -> stylegan_generator.py{class StyleGANGenerator(BaseGenerator))} ->\n",
    "# -> base_generator.py(BaseGenerator) -> class BaseGenerator(def load)\n",
    "\n",
    "# latent_code를 반환해주는 함수\n",
    "def sample_codes(model, num, seed=0, w1k_code=None):\n",
    "  \"\"\"Samples latent codes randomly.\"\"\"\n",
    "  np.random.seed(seed)\n",
    "  if w1k_code is None:\n",
    "    codes = generator.easy_sample(num)\n",
    "    latent_codes = model.easy_sample(num=num, latent_space_type='w')\n",
    "  else:\n",
    "    latent_codes = w1k_code[np.random.randint(0, w1k_code.shape[0], num)]\n",
    "  latent_codes = model.easy_synthesize(latent_codes=latent_codes,\n",
    "                                       latent_space_type='w',\n",
    "                                       generate_style=False,\n",
    "                                       generate_image=False)['wp']\n",
    "  return latent_codes\n",
    "\n",
    "\n",
    "# Boundary 파일 로드 함수 정의\n",
    "def load_boundary(boundary_name, base_dir='boundaries/stylegan_bedroom'):\n",
    "    path = os.path.join(base_dir, boundary_name)\n",
    "    boundary_file = np.load(path, allow_pickle=True).item()\n",
    "    boundary = boundary_file['boundary']\n",
    "    manipulate_layers = boundary_file['meta_data']['manipulate_layers']\n",
    "    return boundary, manipulate_layers\n",
    "\n",
    "# Grad-CAM 계산 함수\n",
    "def calculate_grad_cam(feature_map, gradients):\n",
    "    pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])  # [C]\n",
    "    grad_cam = torch.zeros_like(feature_map[0, 0])\n",
    "    for i in range(feature_map.shape[1]):\n",
    "        grad_cam += pooled_gradients[i] * feature_map[0, i]\n",
    "    grad_cam = torch.relu(grad_cam)  # ReLU 적용\n",
    "    grad_cam -= grad_cam.min()  # 정규화\n",
    "    grad_cam /= grad_cam.max()\n",
    "    return grad_cam.detach().cpu().numpy()\n",
    "\n",
    "# Heatmap을 원본 이미지에 겹쳐서 시각화하는 함수\n",
    "def overlay_heatmap_on_image(image, grad_cam, alpha=0.5, cmap='jet'):\n",
    "    grad_cam_resized = cv2.resize(grad_cam, (image.shape[1], image.shape[0]))\n",
    "    heatmap = cv2.applyColorMap(np.uint8(grad_cam_resized * 255), cv2.COLORMAP_JET)\n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "    if image.max() > 1:\n",
    "        image = image / 255.0\n",
    "    overlayed_image = alpha * heatmap / 255.0 + (1 - alpha) * image\n",
    "    overlayed_image = np.clip(overlayed_image, 0, 1)\n",
    "    return overlayed_image\n",
    "\n",
    "# Heatmap 클러스터링 함수 (DBSCAN 활용)\n",
    "def cluster_heatmap_with_dbscan(heatmap, eps=3, min_samples=5, prob_threshold=0.5):\n",
    "    high_prob_indices = np.argwhere(heatmap >= prob_threshold)\n",
    "    high_prob_values = heatmap[heatmap >= prob_threshold]\n",
    "\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples).fit(high_prob_indices)\n",
    "    labels = db.labels_\n",
    "\n",
    "    clusters = {}\n",
    "    for cluster_id in set(labels):\n",
    "        if cluster_id == -1:  # Noise 처리\n",
    "            continue\n",
    "        cluster_points = high_prob_indices[labels == cluster_id]\n",
    "        cluster_values = high_prob_values[labels == cluster_id]\n",
    "        clusters[cluster_id] = (cluster_points, cluster_values)\n",
    "\n",
    "    return clusters\n",
    "\n",
    "# Hook 설정 함수\n",
    "def setup_hooks(generator, target_layers):\n",
    "    hooks = []\n",
    "\n",
    "    def forward_hook(module, input, output):\n",
    "        module.feature_map = output\n",
    "\n",
    "    def backward_hook(module, grad_in, grad_out):\n",
    "        gradients[module.name] = grad_out[0]\n",
    "\n",
    "    for layer_idx in target_layers:\n",
    "        layer = getattr(generator.net.synthesis, f'layer{layer_idx}')\n",
    "        layer.name = f'layer{layer_idx}'\n",
    "        hooks.append(layer.register_forward_hook(forward_hook))\n",
    "        hooks.append(layer.register_backward_hook(backward_hook))\n",
    "\n",
    "    return hooks\n",
    "\n",
    "# Hook 제거 함수\n",
    "def remove_hooks(hooks):\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "\n",
    "# w1k_code = np.load('order_w_1k.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a59063-0e62-4104-b3b2-5b667d38a370",
   "metadata": {},
   "source": [
    "# input_data 읽어오기(임시)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aedcc0-8610-4a7d-b582-589aa9eb3bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = './input_data'\n",
    "#사용할 임시 경로\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "num_sample_list = []\n",
    "noise_seed_list = []\n",
    "image_num_list = []\n",
    "\n",
    "# 디렉터리 내 파일 순회\n",
    "for file_name in os.listdir(directory_path):\n",
    "    # PNG 파일만 처리\n",
    "    if file_name.endswith('.txt'):\n",
    "        # 파일 이름에서 숫자 추출\n",
    "        try:\n",
    "            # 파일 이름에서 숫자 분리 (예: 100_234_6.png -> [100, 234, 6])\n",
    "            num_sample, noise_seed, image_num = map(int, file_name.rstrip('.txt').split('_'))\n",
    "\n",
    "            # 각 숫자를 리스트에 저장\n",
    "            num_sample_list.append(num_sample)\n",
    "            noise_seed_list.append(noise_seed)\n",
    "            image_num_list.append(image_num)\n",
    "        except ValueError:\n",
    "            print(f\"Invalid file name format: {file_name}\")\n",
    "\n",
    "\n",
    "num_samples = num_sample_list[0]\n",
    "noise_seed = noise_seed_list[0]\n",
    "image_num = image_num_list[0]\n",
    "\n",
    "input_data = [num_samples, noise_seed, image_num]\n",
    "\n",
    "print(\"Num Sample :\", num_samples)\n",
    "print(\"Noise Seed :\", noise_seed)\n",
    "print(\"Image Num :\", image_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "982464ea-e943-4b65-8b20-2e8b60b600e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('higan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb1f1c2-9a97-463f-83c8-17577bc3b318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "\n",
    "# \"models\" 폴더를 python 경로에 추가\n",
    "models_path = os.path.abspath(\"models\")\n",
    "if models_path not in sys.path:\n",
    "    sys.path.append(models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c4b929d-9d12-421f-8c32-51d8a2fd9fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-26 16:52:03,804][INFO] Build generator for model `stylegan_bedroom`.\n",
      "[2024-12-26 16:52:03,985][INFO] Loading pytorch weights from `models/pretrain/pytorch/stylegan_bedroom256_generator.pth`.\n",
      "[2024-12-26 16:52:04,121][INFO] Successfully loaded!\n",
      "[2024-12-26 16:52:04,127][INFO] Current `lod` is 0.0.\n"
     ]
    }
   ],
   "source": [
    "#indoor_model_name = \"stylegan_bedroom\"\n",
    "#indoor_model = build_model(indoor_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca7cd4e-cb3b-403a-b967-a70ea02a8733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d609b4b3-71ec-44ac-9c8c-244c9721b332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    model_info_dict = exec_init_model()\n",
    "    return{**model_info_dict}\n",
    "\n",
    "def inference_dataframe(input_data, model_info_dict):\n",
    "    result = exec_inference_dataframe(input_data, model_info_dict)\n",
    "    return{**result}\n",
    "\n",
    "# def inference_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1aed19-59ef-47be-bdaf-d5a3a223dd2f",
   "metadata": {},
   "source": [
    "# inference_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf5877b-111a-4bff-a550-75525210b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator 모델 로드\n",
    "from stylegan_generator import StyleGANGenerator\n",
    "from model_settings import MODEL_POOL\n",
    "    \n",
    "def exec_init_model():\n",
    "    indoor_model_name = \"stylegan_bedroom\"\n",
    "    model = build_model(indoor_model_name)\n",
    "    model_info_dict = {\n",
    "        \"model\": model\n",
    "    }\n",
    "    return model_info_dict\n",
    "\n",
    "def exec_inference_dataframe(input_data, model_info_dict):\n",
    "    # 학습 모델, latent space 준비\n",
    "    indoor_model = model_info_dict['model']\n",
    "    w1k_code = np.load('order_w_1k.npy')\n",
    "    \n",
    "    # input_data(이미지) 불러오기\n",
    "    # input_data[0] : num_sample, input_data[1] : noise_seed, input_data[2] : image_num\n",
    "    indoor_latent_codes = sample_codes(indoor_model, input_data[0], input_data[1], w1k_code=w1k_code)\n",
    "    synthesis_kwargs = {'latent_space_type': 'wp'}\n",
    "    images = indoor_model.easy_synthesize(indoor_latent_codes, **synthesis_kwargs)['image']\n",
    "    \n",
    "    # boundary통한 latent code 조작으로 laten_code1 생성\n",
    "    path = f'boundaries/{indoor_model_name}/{attribute_name}_boundary.npy'\n",
    "    #print(f'Loading boundary from {path}')\n",
    "    try:\n",
    "      boundary_file = np.load(path, allow_pickle=True).item()\n",
    "      boundary = boundary_file['boundary']\n",
    "      manipulate_layers = boundary_file['meta_data']['manipulate_layers']\n",
    "    except ValueError:\n",
    "      boundary = np.load(path)\n",
    "      if attribute_name == 'view':\n",
    "        manipulate_layers = '0-4'\n",
    "      else:\n",
    "        manipulate_layers = '6-11'\n",
    "        \n",
    "    if attribute_name == 'view':\n",
    "      strength = [1.0 for _ in range(indoor_model.num_layers)]\n",
    "    else:\n",
    "      strength = get_layerwise_manipulation_strength(\n",
    "        indoor_model.num_layers, indoor_model.truncation_psi, indoor_model.truncation_layers)\n",
    "\n",
    "    distance = -3 # {min:-3.0, max:3.0, step:0.1}\n",
    "    latent_code1 = manipulate(latent_codes=indoor_latent_codes,\n",
    "                         boundary=boundary,\n",
    "                         start_distance=0,\n",
    "                         end_distance=distance,\n",
    "                         step=2,\n",
    "                         layerwise_manipulation=True,\n",
    "                         num_layers=indoor_model.num_layers,\n",
    "                         manipulate_layers=manipulate_layers,\n",
    "                         is_code_layerwise=True,\n",
    "                         is_boundary_layerwise=False,\n",
    "                         layerwise_manipulation_strength=strength)\n",
    "    distance = 3 #{min:-3.0, max:3.0, step:0.1}\n",
    "    latent_code2 = manipulate(latent_codes=indoor_latent_codes,\n",
    "                         boundary=boundary,\n",
    "                         start_distance=0,\n",
    "                         end_distance=distance,\n",
    "                         step=2,\n",
    "                         layerwise_manipulation=True,\n",
    "                         num_layers=indoor_model.num_layers,\n",
    "                         manipulate_layers=manipulate_layers,\n",
    "                         is_code_layerwise=True,\n",
    "                         is_boundary_layerwise=False,\n",
    "                         layerwise_manipulation_strength=strength)\n",
    "    \n",
    "    # layer별 feature map 확인 위해 generator load\n",
    "    model_name = 'stylegan_bedroom'\n",
    "    generator = StyleGANGenerator(model_name=model_name)\n",
    "    generator.weight_path = MODEL_POOL[model_name]['weight_path']\n",
    "    generator.load()\n",
    "    generator.net.eval()\n",
    "    \n",
    "    # Gradients 저장 변수\n",
    "    gradients = {}\n",
    "    \n",
    "    # Grad-CAM 계산을 위한 설정\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    generator.net.to(device)\n",
    "\n",
    "    # ΔGrad-CAM 계산을 위한 준비\n",
    "    latent_codes = [latent_codes1, latent_codes2]\n",
    "    results = []\n",
    "    aggregate_grad_cam = None  # 초기화\n",
    "    target_resolution = (256, 256)  # 원하는 Heatmap 해상도 (e.g., 최종 이미지 해상도)\n",
    "\n",
    "    sample_index = image_num  # 사용할 샘플 인덱스\n",
    "    step_index = 1  # 0: 조작 전, 1: 조작 후 상태\n",
    "\n",
    "\n",
    "    # 레이어별 비율 설정\n",
    "    layer_percentages = {6: 1.0, 7: 1.0, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0}\n",
    "    \n",
    "    for layer_idx in range(6, 12):  # Layer 6~11\n",
    "        grad_cams = []\n",
    "\n",
    "        for latent_idx, latent_code in enumerate(latent_codes):\n",
    "            if len(latent_code.shape) == 4:  # [N, Steps, L, D]\n",
    "                latent_code = latent_code[sample_index, step_index, :, :]  # 샘플과 Step 선택\n",
    "            elif len(latent_code.shape) == 3:  # [N, L, D]\n",
    "                latent_code = latent_code[sample_index, :, :]\n",
    "            latent_code = torch.from_numpy(latent_code).unsqueeze(0).float().to(device)\n",
    "            latent_code.requires_grad = True\n",
    "\n",
    "            # Hook 설정\n",
    "            hooks = setup_hooks(generator, [layer_idx])\n",
    "\n",
    "            # Latent Code 처리\n",
    "            generated_output = generator.net.synthesis(latent_code)\n",
    "\n",
    "            # Feature Map 및 Grad-CAM 계산\n",
    "            layer = getattr(generator.net.synthesis, f'layer{layer_idx}')\n",
    "            feature_map = layer.feature_map\n",
    "            num_channels = feature_map.shape[1]\n",
    "\n",
    "            boundary_layer = boundary[0, :num_channels]\n",
    "            boundary_broadcasted = torch.tensor(boundary_layer[:, np.newaxis, np.newaxis]).to(device)\n",
    "\n",
    "            influence_map = torch.sum(feature_map * boundary_broadcasted, dim=[2, 3])\n",
    "            top_percentage = layer_percentages.get(layer_idx, 0.1)\n",
    "            num_top_channels = max(1, int(num_channels * top_percentage))\n",
    "            top_channels = torch.argsort(influence_map[0], descending=True)[:num_top_channels]\n",
    "\n",
    "            score = torch.sum(feature_map[0, top_channels])\n",
    "            generator.net.zero_grad()\n",
    "            score.backward(retain_graph=True)\n",
    "\n",
    "            grad_cam = calculate_grad_cam(feature_map, gradients[layer.name])\n",
    "            grad_cams.append(grad_cam)\n",
    "\n",
    "            # Hook 제거\n",
    "            remove_hooks(hooks)\n",
    "        # ΔGrad-CAM 계산\n",
    "        if len(grad_cams) == 2:\n",
    "            grad_cam_diff = grad_cams[1] - grad_cams[0]\n",
    "            grad_cam_diff = np.clip(grad_cam_diff / (grad_cam_diff.max() - grad_cam_diff.min()), 0, 1)\n",
    "\n",
    "            # Heatmap 크기 정규화\n",
    "            grad_cam_diff_resized = cv2.resize(grad_cam_diff, target_resolution)\n",
    "\n",
    "            # ΔGrad-CAM 누적\n",
    "            if aggregate_grad_cam is None:\n",
    "                aggregate_grad_cam = grad_cam_diff_resized\n",
    "            else:\n",
    "                aggregate_grad_cam += grad_cam_diff_resized\n",
    "                \n",
    "    # 최대 표시할 recommend 개수 설정\n",
    "    max_recommend_to_display = 3  # 최대 표시할 recommend 개수\n",
    "    \n",
    "    # Aggregate ΔGrad-CAM 계산 및 DBSCAN 클러스터링\n",
    "    if aggregate_grad_cam is not None:\n",
    "        aggregate_grad_cam_normalized = aggregate_grad_cam / aggregate_grad_cam.max()\n",
    "\n",
    "        clusters = cluster_heatmap_with_dbscan(aggregate_grad_cam_normalized, eps=5, min_samples=40, prob_threshold=0.5)\n",
    "\n",
    "        # 클러스터를 높은 Heat 비중으로 정렬\n",
    "        cluster_scores = {\n",
    "            cluster_id: np.mean(cluster_values) for cluster_id, (_, cluster_values) in clusters.items()\n",
    "        }\n",
    "        sorted_clusters = sorted(cluster_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # 최대 표시할 recommend 개수 제한\n",
    "        sorted_clusters = sorted_clusters[:max_recommend_to_display]\n",
    "\n",
    "        latent_codes1 = latent_codes1[sample_index, : , :, :]\n",
    "        latent_codes2 = torch.from_numpy(latent_codes2[sample_index, step_index , :, :]).unsqueeze(0).to(device).float()  # [1, 14, 512]\n",
    "\n",
    "        generated_image_1 = indoor_model.easy_synthesize(latent_codes1, latent_space_type='wp')['image']\n",
    "        generated_image_1 = generated_image_1[1]\n",
    "\n",
    "        generated_image_2 = generator.net.synthesis(latent_codes2).detach().cpu().numpy()\n",
    "        generated_image_2 = np.transpose(generated_image_2[0], (1, 2, 0))  # [1, 3, 256, 256] -> [256, 256, 3]\n",
    "        generated_image_2 = np.clip(generated_image_2, 0, 1)\n",
    "\n",
    "        # 최종 시각화\n",
    "        result_image_2 = overlay_heatmap_on_image(generated_image_2, aggregate_grad_cam_normalized)\n",
    "\n",
    "        # 결과 시각화: heatmap 포함 결과와 포함되지 않은 결과를 나란히 표시\n",
    "        fig, axes = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "        # Heatmap이 포함된 결과\n",
    "        mappable = axes.imshow(result_image_2)  # Heatmap 포함된 결과\n",
    "        axes.set_title(f\"Result with Heatmap (Top {max_recommend_to_display} Recommends)\")\n",
    "        plt.colorbar(mappable, ax=axes)  # Colorbar 추가\n",
    "\n",
    "        scaling_factor = 3.0\n",
    "\n",
    "        cluster_centers = []\n",
    "        \n",
    "        # 상위 recommend의 타원과 상위 포인트 표시 (Heatmap 포함된 결과)\n",
    "        for i, (cluster_id, _) in enumerate(sorted_clusters):\n",
    "            points, values = clusters[cluster_id]\n",
    "            top_point = points[np.argmax(values)]\n",
    "            y, x = top_point\n",
    "\n",
    "           # 타원 중심과 범위 계산\n",
    "            cluster_center = np.mean(points, axis=0)\n",
    "            covariance_matrix = np.cov(points, rowvar=False)\n",
    "            eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "            major_axis = scaling_factor * 2 * np.sqrt(eigenvalues[1])  # 주축\n",
    "            minor_axis = scaling_factor * 2 * np.sqrt(eigenvalues[0])  # 부축\n",
    "\n",
    "            # 타원의 각도를 항상 수직으로 설정 (90도)\n",
    "            angle = 90.0\n",
    "            cluster_centers.append({\n",
    "            \"cluster_id\": cluster_id,\n",
    "            \"center_y\": cluster_center[0],\n",
    "            \"center_x\": cluster_center[1]\n",
    "            })\n",
    "            print(f\"Cluster {i + 1} Center Coordinates: (y: {cluster_center[0]:.2f}, x: {cluster_center[1]:.2f})\")\n",
    "\n",
    "\n",
    "        # 타원 추가\n",
    "            ellipse = patches.Ellipse(\n",
    "                cluster_center[::-1], width=major_axis, height=minor_axis, angle=angle,\n",
    "                edgecolor='red', facecolor='none', linewidth=2\n",
    "            )\n",
    "            axes.add_patch(ellipse)\n",
    "\n",
    "            # 상위 recommend 포인트 표시\n",
    "            axes.scatter(x, y, color='lime', edgecolors='black', linewidth=2, s=100)\n",
    "            axes.text(x + 5, y, f\"Recommend {i+1}\", color='lime', fontsize=12, weight='bold')\n",
    "    \n",
    "    axes.axis('off')\n",
    "    \n",
    "    # 상위 recommend의 타원과 상위 포인트 표시 (원본 이미지)\n",
    "    for i, (cluster_id, _) in enumerate(sorted_clusters):\n",
    "        points, values = clusters[cluster_id]\n",
    "        top_point = points[np.argmax(values)]\n",
    "        y, x = top_point\n",
    "\n",
    "        # 타원 중심과 범위 계산\n",
    "        cluster_center = np.mean(points, axis=0)\n",
    "        covariance_matrix = np.cov(points, rowvar=False)\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "        major_axis = scaling_factor * 2 * np.sqrt(eigenvalues[1])  # 주축\n",
    "        minor_axis = scaling_factor * 2 * np.sqrt(eigenvalues[0])  # 부축\n",
    "        # 타원의 각도를 항상 수직으로 설정 (90도)\n",
    "        angle = 90.0\n",
    "\n",
    "        # 타원 추가\n",
    "        ellipse = patches.Ellipse(\n",
    "            cluster_center[::-1], width=major_axis, height=minor_axis, angle=angle,\n",
    "            edgecolor='blue', facecolor='none', linewidth=2\n",
    "        )\n",
    "        axes.add_patch(ellipse)\n",
    "\n",
    "        # 상위 recommend 포인트 표시\n",
    "        axes.scatter(x, y, color='orange', edgecolors='black', linewidth=2, s=100)\n",
    "        axes.text(x + 5, y, f\"Recommend {i+1}\", color='lime', fontsize=12, weight='bold')\n",
    "        \n",
    "    axes.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b380f8-9d2d-4f20-91ca-7e5b619acd6a",
   "metadata": {},
   "source": [
    "# inference_service_sub.py\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image\n",
    "import ast\n",
    "\n",
    "\"\"\"\n",
    "from t3qai_client import DownloadFile\n",
    "import t3qai_client as tc\n",
    "from t3qai_client import T3QAI_MODULE_PATH, T3QAI_INIT_MODEL_PATH\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def exec_init_model():\n",
    "    model_path = os.path.join(T3QAI_INIT_MODEL_PATH, 'stylegan_bedroom256_generator.pth')\n",
    "    model = load_model(model_path)\n",
    "    model_info_dict = {\n",
    "        \"model\": model\n",
    "    }\n",
    "    return model_info_dict\n",
    "\n",
    "def exec_inference_dataframe(input_data, model_info_dict):\n",
    "    \n",
    "    logging.info('[hunmin log] the start line of the function [exec_inference_dataframe]')\n",
    "    \n",
    "    ## 학습 모델 준비\n",
    "    model = model_info_dict['model']\n",
    "    labels = ['10_10-5', '10_140_5', '10_156_0', '10_445_6', '10_864_0']\n",
    "\n",
    "    # 파일 내용 읽기 및 처리\n",
    "    for data_entry in input_data:\n",
    "        try:\n",
    "            # 문자열로 된 리스트를 파이썬 리스트로 변환\n",
    "            data = ast.literal_eval(data_entry)\n",
    "            # 리스트를 NumPy 배열로 변환\n",
    "            data = np.array(data)\n",
    "        except (ValueError, SyntaxError) as e:\n",
    "            logging.error(f'Error processing data: {e}')\n",
    "            continue\n",
    "    \n",
    "    # data predict\n",
    "    y_pred = model.predict(data, verbose=0)\n",
    "    y_pred_idx = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    # inverse transform\n",
    "    result = {'inference' : [labels[y_pred_idx[0]]]}\n",
    "    logging.info('[hunmin log] result : {}'.format(result))\n",
    "\n",
    "    return result\n",
    "\n",
    "def exec_inference_file(files, model_info_dict):\n",
    "    \n",
    "    \"\"\"파일기반 추론함수는 files와 로드한 model을 전달받습니다.\"\"\"\n",
    "    logging.info('[hunmin log] the start line of the function [exec_inference_file]')\n",
    "    model = model_info_dict['model']\n",
    "\n",
    "    inference_result = []\n",
    "    \n",
    "    for one_file in files:\n",
    "        filename = one_file['filename']\n",
    "        logging.info(f'[hunmin log] inference: {filename}')\n",
    "\n",
    "        # 파일 열기 및 내용 읽기\n",
    "        try:\n",
    "            with open(one_file['file'], 'r') as file:\n",
    "                content = file.read().strip()\n",
    "                # 문자열로 된 리스트를 파이썬 리스트로 변환\n",
    "                data = ast.literal_eval(content)\n",
    "                # 리스트를 NumPy 배열로 변환\n",
    "                data = np.array(data)\n",
    "        except ValueError as e:\n",
    "            logging.error(f'Error reading or processing data from file {filename}: {e}')\n",
    "            continue\n",
    "        except SyntaxError as e:\n",
    "            logging.error(f'Syntax error in file {filename}: {e}')\n",
    "            continue\n",
    "\n",
    "        # 모델 예측\n",
    "        y_pred = model.predict(data, verbose=0)\n",
    "        y_pred_idx = np.argmax(y_pred, axis=1)\n",
    "        \n",
    "        inference_result.append([y_pred_idx[0]])\n",
    "\n",
    "    result = {'inference': inference_result}\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "drawn-original",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_data:  [[10, 449, 4]]\n",
      "T3QAI_TRAIN_OUTPUT_PATH: ./meta_data/output\n",
      "T3QAI_TRAIN_MODEL_PATH: ./meta_data/model_path\n",
      "T3QAI_TRAIN_DATA_PATH: ./meta_data/dataset\n",
      "T3QAI_MODULE_PATH: ./\n",
      "T3QAI_INIT_MODEL_PATH: ./meta_data/model_path\n"
     ]
    }
   ],
   "source": [
    "# 플랫폼 내부 기능을 재현하기 위해 만들어 놓은 부분\n",
    "# 아래 1,2,3번을 제외한 부분은 절대 수정하지 말고 진행할 것\n",
    "# 수정 가능한 내용(이외 내용 임의 수정 불가. 모르는 부분은 담당자 문의 후 진행할 것)\n",
    "# 1. t3qai_client클래스 내 train_load_param 함수의 내부 변수 - 파라미터 조정하는 부분이라 매뉴얼을 참고하여 파라미터 추가 가능, 파라미터 정의하지 않고도 사용 가능\n",
    "# 2. 추론 입력 예시 데이터인 input_data 내용 수정 가능 - 형식은 [[]] 이중리스트 안에 원하는 데이터를 넣는 형태로 진행할 것\n",
    "# 3. 플랫폼에서 데이터셋 업로드시 자동으로 dataset폴더에 데이터셋 압축이 풀리기 때문에 1번파일에서 dataset.zip파일을 zip_file 함수를 통해 압축해제한다.\n",
    "#    dataset.zip의 이름과 extractall 경로 마지막 폴더이름(dataset)을 같게 작성한다.\n",
    "#    ex) images.zip이면 extractall('meta_data/dataset/images')로 정한다.\n",
    "\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import base64\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "import ipywidgets\n",
    "from ipywidgets import FileUpload\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# 1. t3qai_client 클래스: t3qai_client 객체\n",
    "class t3qai_client:\n",
    "    def train_start(self):\n",
    "        return None\n",
    "\n",
    "    def train_finish(self, result, result_msg):\n",
    "        if result_msg != \"success\":\n",
    "            raise Exception(result_msg)\n",
    "        else:\n",
    "            logging.info(result)\n",
    "            logging.info(\"train finish\")\n",
    "\n",
    "    def train_load_param(self):\n",
    "        '''set_param 해당 부분 수정하여\n",
    "          파라미터 조정 가능'''\n",
    "        epoch = 20\n",
    "        batch_size = 16\n",
    "        params = {\"epoch\" : epoch, 'batch_size' : batch_size}\n",
    "        return { **params }\n",
    "\n",
    "# 2. 추론 입력 데이터 정의\n",
    "# input_data = [['iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAACySURBVEhL7ZLRDoAgCEWt//9nc8EIEepStvXQeWkyPEKw1FrLbFb+TuWXzichXXb4cAokJR0tH+JFK21G8V6CSqlApMxGelBIsVBHeOOEzZYGdRzpussfL7eIazHPa0wrx0GMdBSiuMbkdINyb5og0gRL3dTbcPtNOpYZveQ2pA1n0hTakF5+hA9Lzd87pNFYLhkvsvT2lMhorndluxkRUuCYbzcp9ROi55+up8sLK1XKBj1wbx3DelAOAAAAAElFTkSuQmCC']]\n",
    "input_data = [[10,449,4]]\n",
    "print('input_data: ', input_data)\n",
    "\n",
    "# 3. dataset 압축해제 함수\n",
    "def zip_file():\n",
    "    my_zip_path = '../T3Q_PLATFORM_GUIDE_image_classification/dataset.zip'\n",
    "    extract_zip_file = zipfile.ZipFile(my_zip_path)\n",
    "    extract_zip_file.extractall('./meta_data/dataset/dataset')\n",
    "    extract_zip_file.close()\n",
    "zip_file()\n",
    "\n",
    "# 파일 업로드 클래스 정의\n",
    "class UploadFile:\n",
    "    def __init__(self, file, filename):\n",
    "        self.file = file\n",
    "        self.filename = filename\n",
    "        \n",
    "# 다운로드 파일 함수 정의\n",
    "def DownloadFile(file_name, file_obj = None, file_path = None):\n",
    "    file_route = './meta_data/DownloadFiles'\n",
    "    os.makedirs(file_route, exist_ok = True)\n",
    "    file_dir = os.path.join(file_route, file_name)\n",
    "    if (file_obj == None) == (file_path == None):\n",
    "        Err_msg = \"[DownloadFile Error]: Only one of the 'file_path' or 'file_obj' arguments is required.\"\n",
    "        Err_msg += f\"{0 if file_obj==None else 2} arguments entered.\"\n",
    "        raise Exception(Err_msg)\n",
    "    elif(file_obj != None):\n",
    "        file_obj.seek(0)\n",
    "        file_read = base64.b64encode(file_obj.read()).decode('utf-8')\n",
    "        binary_file = base64.b64decode(file_read)\n",
    "        with open(file_dir, 'wb') as f:\n",
    "            f.write(binary_file)\n",
    "    elif(file_path != None):\n",
    "        shutil.copyfile(file_path, file_dir)\n",
    "        \n",
    "    return FileLink(file_dir)\n",
    "\n",
    "# 플랫폼 내 정의된 경로 변수(임의 수정 불가)\n",
    "T3QAI_TRAIN_OUTPUT_PATH = './meta_data/output'\n",
    "T3QAI_TRAIN_MODEL_PATH = './meta_data/model_path'\n",
    "T3QAI_TRAIN_DATA_PATH = './meta_data/dataset'\n",
    "# T3QAI_TEST_DATA_PATH = './meta_data'\n",
    "T3QAI_MODULE_PATH = './'\n",
    "T3QAI_INIT_MODEL_PATH = './meta_data/model_path'\n",
    "\n",
    "# t3qai_client 객체\n",
    "tc = t3qai_client()\n",
    "print('T3QAI_TRAIN_OUTPUT_PATH:', T3QAI_TRAIN_OUTPUT_PATH)\n",
    "print('T3QAI_TRAIN_MODEL_PATH:', T3QAI_TRAIN_MODEL_PATH)\n",
    "print('T3QAI_TRAIN_DATA_PATH:', T3QAI_TRAIN_DATA_PATH)\n",
    "# print('T3QAI_TEST_DATA_PATH:', T3QAI_TEST_DATA_PATH)\n",
    "print('T3QAI_MODULE_PATH:', T3QAI_MODULE_PATH)\n",
    "print('T3QAI_INIT_MODEL_PATH:', T3QAI_INIT_MODEL_PATH)\n",
    "\n",
    "# 경로로 사용되는 폴더 생성 함수\n",
    "def createDirectory(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        logging.info(\"Error: Failed to create the directory.\")\n",
    "\n",
    "createDirectory(T3QAI_TRAIN_MODEL_PATH)\n",
    "createDirectory(T3QAI_TRAIN_OUTPUT_PATH)\n",
    "\n",
    "\n",
    "# inference_file 파일 업로드 함수\n",
    "files = []\n",
    "\n",
    "uploader = FileUpload(accept='*', multiple=True, description='select data', button_style='danger')\n",
    "def uploader_change(change):\n",
    "    uploader.button_style='success'\n",
    "    count = len(uploader.value)\n",
    "    uploader._counter = count\n",
    "    files.clear()\n",
    "    for file_num in range(count):\n",
    "        temp_data = tempfile.TemporaryFile()\n",
    "        if ipywidgets.__version__[0] == '7':\n",
    "            temp_data.write(list(uploader.value.values())[file_num]['content'])\n",
    "            file = UploadFile(temp_data, pd.DataFrame(list(uploader.value.values())[file_num]).iloc[1,0])\n",
    "        elif int(ipywidgets.__version__[0]) > 7:\n",
    "            temp_data.write(uploader.value[file_num].content)\n",
    "            file = UploadFile(temp_data, uploader.value[file_num].name)\n",
    "        files.append(file)\n",
    "\n",
    "uploader.observe(uploader_change, 'value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "assigned-david",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:error log : name 'exec_train' is not defined\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "name 'exec_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19828\\2021458836.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mresult_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error log : {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mtc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_finish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19828\\1945622341.py\u001b[0m in \u001b[0;36mtrain_finish\u001b[1;34m(self, result, result_msg)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain_finish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult_msg\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"success\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: name 'exec_train' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# main() 함수에서 train() 함수 실행\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "tutorial-robert",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (file signature not found)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19828\\2845122304.py\u001b[0m in \u001b[0;36minit_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mmodel_info_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexec_init_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[hunmin log] the end line of the function [init_model]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmodel_info_dict\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19828\\1372994502.py\u001b[0m in \u001b[0;36mexec_init_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mexec_init_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mmodel_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT3QAI_INIT_MODEL_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'stylegan_bedroom256_generator.pth'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;31m# 모델 가중치 로드\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\higan\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    144\u001b[0m       h5py is not None and (\n\u001b[0;32m    145\u001b[0m           isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[1;32m--> 146\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\higan\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    198\u001b[0m   \u001b[0mopened_new_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\higan\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    565\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[1;32m--> 567\u001b[1;33m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\higan\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (file signature not found)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_info_dict = init_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-transition",
   "metadata": {},
   "source": [
    "### CASE [추론 입력 타입 - 추론 출력 타입] : 총 4가지\n",
    "추론 입력 타입 : DataFrame &rarr; 추론 출력 타입 : Dictionary (1가지)    \n",
    "추론 입력 타입 : File &rarr; 추론 출력 타입 : Dictionary, DownloadFile, DownloadFile의 List (3가지)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "needed-motel",
   "metadata": {},
   "source": [
    "### CASE  [DataFrame - Dictionary]\n",
    "DataFrame 입력에 대한 추론 결과를 딕셔너리(Dictionary) 형태로 리턴(return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "guilty-membrane",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_info_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_info_dict' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "inference_dataframe(input_data, model_info_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-behavior",
   "metadata": {},
   "source": [
    "### CASE  [File - Dictionary]\n",
    "File 에 대한 추론 결과를 딕셔너리(Dictionary) 형태로 리턴(return)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-advance",
   "metadata": {},
   "source": [
    " 1. 아래 Cell을 실행하면 select data 버튼이 생성됩니다.\n",
    " 2. 생성된 select data 버튼을 눌러 추론할 데이터를 선택하세요.\n",
    " 3. 선택 후 **inference_file(files, model_info_dict)** 을 실행하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial-witness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91e146843df4962939c8ff8a299c1f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='*', button_style='danger', description='select data', multiple=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# uploader widget(해당 커널 output의 버튼)에 파일을 업로드 한 뒤 infernece_file으로 추론합니다.\n",
    "display(uploader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "alert-bridges",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_info_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_info_dict' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "inference_file(files, model_info_dict)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "image_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
